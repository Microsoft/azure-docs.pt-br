---
author: v-demjoh
ms.service: cognitive-services
ms.topic: include
ms.date: 9/22/2020
ms.author: v-demjoh
ms.openlocfilehash: bc67c3433c939be39453c954ada1171dc210b692
ms.sourcegitcommit: 17b36b13857f573639d19d2afb6f2aca74ae56c1
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 11/10/2020
ms.locfileid: "94425090"
---
Você pode transcrever uma fala em texto usando o SDK de Fala para Swift e Objective-C.

## <a name="prerequisites"></a>Pré-requisitos

Os exemplos a seguir pressupõem que você tenha uma conta do Azure e uma assinatura do serviço de Fala. Se você não tiver uma conta e uma assinatura, [experimente o serviço de Fala gratuitamente](../../../overview.md#try-the-speech-service-for-free).

## <a name="install-speech-sdk-and-samples"></a>Instalar o SDK de Fala e exemplos

O [SDK de Fala dos Serviços Cognitivos](https://github.com/Azure-Samples/cognitive-services-speech-sdk) contém exemplos escritos em Swift e Objective-C para iOS e Mac. Clique em um link para ver as instruções de instalação de cada exemplo:

* [Reconhecer uma fala de um microfone em Objective-C no macOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/objectivec/macos/from-microphone)
* [Reconhecer uma fala em Swift no macOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/swift/macos/from-microphone)
* [Reconhecer uma fala em Objective-C no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/objectivec/ios/from-microphone)
* [Reconhecer uma fala em Swift no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/swift/ios/from-microphone)
* [Exemplos adicionais para Objective-C no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/objective-c/ios)

Também fornecemos uma [Referência de SDK de Fala para Objective-C](/objectivec/cognitive-services/speech/) online.